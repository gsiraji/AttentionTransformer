{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# import the libraries\n","\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import math, copy, time\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sn "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create the encoder-decoder class\n","\n","class EncoderDecoder(nn.Module):\n","    \"\"\"\n","    Base class for the model\n","    encoder maps input seq to a representation\n","    decoder maps rep to an output seq\n","    \"\"\"\n","\n","    def __init__(self, encoder, decoder, source_embed,\n","                  target_embed, generator):\n","        super(EncoderDecoder, self).__init__\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.source_embed = source_embed\n","        self.target_embed = target_embed\n","        self.generator = generator\n","\n","    def forward(self, source, target, \n","                source_mask, target_mask):\n","        \n","        return self.decode(self.encode(source, source_mask),\n","                           source_mask, target,target_mask)\n","    \n","    def encode(self,source,source_mask):\n","        return self.decoder(self.source_embed(source), source_mask)\n","    \n","    def decode(self, memory, source_mask, target, target_mask):\n","        return self.decoder(self.tgt_embed(target), memory, source_mask, target_mask)\n","    \n","\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Generator(nn.Module):\n","     \"\"\"\n","    Base generator class for the model\n","    perform linear and log softmax\n","    \"\"\"\n","     \n","     def __init__(self, d_model, vocabulary) -> None:\n","          super(Generator, self).__init__()\n","          self.project = nn.Linear(d_model, vocabulary)\n","\n","     def forward(self,x):\n","          # log(exp(x_i)/sum_j(exp(x_j)))\n","          return F.log_softmax(self.project(x), dim=-1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# The Encoder Stack\n","\n","# create 6 identical layers for the encoder\n","\n","def clone(layer, number_of_layers):\n","    \"make number_of_layers clones of a layer\"\n","    return nn.ModuleList([copy.deepcopy(layer) for _ in range(number_of_layers)])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
